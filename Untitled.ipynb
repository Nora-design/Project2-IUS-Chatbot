{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12035775-dde8-4044-b9c5-3e756c7d107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prevent the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dcd33a6-6cfd-4f3f-86e3-5558d267a251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\emre sevinç\\appdata\\roaming\\python\\python311\\site-packages (25.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\emre sevinç\\appdata\\roaming\\python\\python311\\site-packages (80.7.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\emre sevinç\\appdata\\roaming\\python\\python311\\site-packages (0.45.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753e013f-d6a9-4a0c-a88b-48d47beefa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c54bf8-5017-44bd-9c3c-9ef6c78dcc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-stack\n",
      "  Using cached llama_stack-0.2.6-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting blobfile (from llama-stack)\n",
      "  Using cached blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting fire (from llama-stack)\n",
      "  Using cached fire-0.7.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [14 lines of output]\n",
      "  ERROR: Can not execute `setup.py` since setuptools failed to import in the build environment with exception:\n",
      "  Traceback (most recent call last):\n",
      "    File \"<pip-setuptools-caller>\", line 14, in <module>\n",
      "    File \"C:\\Users\\Emre Sevinç\\AppData\\Roaming\\Python\\Python311\\site-packages\\setuptools\\__init__.py\", line 26, in <module>\n",
      "      from .dist import Distribution\n",
      "    File \"C:\\Users\\Emre Sevinç\\AppData\\Roaming\\Python\\Python311\\site-packages\\setuptools\\dist.py\", line 20, in <module>\n",
      "      from . import (\n",
      "    File \"C:\\Users\\Emre Sevinç\\AppData\\Roaming\\Python\\Python311\\site-packages\\setuptools\\_entry_points.py\", line 6, in <module>\n",
      "      from jaraco.text import yield_lines\n",
      "    File \"C:\\Users\\Emre Sevinç\\AppData\\Roaming\\Python\\Python311\\site-packages\\setuptools\\_vendor\\jaraco\\text\\__init__.py\", line 12, in <module>\n",
      "      from jaraco.context import ExceptionTrap\n",
      "    File \"C:\\Users\\Emre Sevinç\\AppData\\Roaming\\Python\\Python311\\site-packages\\setuptools\\_vendor\\jaraco\\context.py\", line 17, in <module>\n",
      "      from backports import tarfile\n",
      "  ImportError: cannot import name 'tarfile' from 'backports' (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\backports\\__init__.py)\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a8236a-766d-4700-ade2-a33ffafe9282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.3.9.tar.gz (67.9 MB)\n",
      "     ---------------------------------------- 0.0/67.9 MB ? eta -:--:--\n",
      "     - -------------------------------------- 2.6/67.9 MB 18.9 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 8.4/67.9 MB 22.6 MB/s eta 0:00:03\n",
      "     ------- ------------------------------- 13.6/67.9 MB 23.1 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 18.4/67.9 MB 23.6 MB/s eta 0:00:03\n",
      "     ------------- ------------------------- 23.6/67.9 MB 23.3 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 28.3/67.9 MB 23.3 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 33.3/67.9 MB 23.7 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 38.3/67.9 MB 23.6 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 43.0/67.9 MB 23.8 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 48.2/67.9 MB 23.6 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 53.2/67.9 MB 23.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 58.2/67.9 MB 23.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 63.2/67.9 MB 23.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  67.6/67.9 MB 23.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 67.9/67.9 MB 22.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from llama-cpp-python) (4.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from llama-cpp-python) (1.26.4)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from llama-cpp-python) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.3)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): still running...\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.9-cp311-cp311-win_amd64.whl size=3360579 sha256=60f70b7920976280196230011415a1775106b1fc2a403af9882ab211e0b8a2af\n",
      "  Stored in directory: c:\\users\\emre sevinç\\appdata\\local\\pip\\cache\\wheels\\9e\\8f\\bf\\148c8eb7d69021eccd6eae6444f3accd48347587054ffd24e5\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "\n",
      "   -------------------- ------------------- 1/2 [llama-cpp-python]\n",
      "   ---------------------------------------- 2/2 [llama-cpp-python]\n",
      "\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.9\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
